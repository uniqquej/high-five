<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>face detection</title>
    <script async src="opencv.js" onload="onOpenCvReady();"></script>
</head>
<body>
    <div class="container">
        <video id="videoInput" width="640" height="480" autoplay playsinline muted style="position:absolute; top:0; left:0;"></video>

        <canvas id="canvasOutput" width="640" height="480" style="position:absolute; top:0; right:0;"></canvas>
    </div>
    <button type="button" id="toggleStream1" onclick="toggleStream()">play</button>
</body>

<script>
    let  src, dst, cap,gray,faces,classifier;
    let video,canvas, context;
    let streaming=false;
    const faceCascadeFile = "haarcascade_frontalface_default.xml";
    function onOpenCvReady() {
        cv['onRuntimeInitialized']=()=>{
            console.log('load')
            video = document.getElementById('videoInput');
            canvas = document.getElementById("canvasOutput");
            cap = new cv.VideoCapture(video);
            src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            gray = new cv.Mat();
            faces = new cv.RectVector();
            classifier = new cv.CascadeClassifier();
            
            app();
        }
    }
    let webcam;
    async function app(){
        classifier.load(faceCascadeFile);
        console.log('classifier : ',classifier.empty())
        webcam = await navigator.mediaDevices.getUserMedia({ video: true, audio: false })
        video.srcObject = webcam;
        context = canvas.getContext('2d');
        
        streaming = true
        setTimeout(processVideo, 0);
        }

        const FPS = 30;

    function processVideo() {
        try {
            console.log('process')
            context.drawImage(video, 0, 0);
            if (!streaming) {
                console.log('streaming=false')
                // clean and stop.
                src.delete();
                dst.delete();
                gray.delete();
                faces.delete();
                classifier.delete();
                return;
            }
            let begin = Date.now();
            // start processing.
            cap.read(src);
            src.copyTo(dst);
            cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY,0);
            classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
            // draw faces.
            for (let i = 0; i < faces.size(); ++i) {
                console.log("faces: ",faces)
                let face = faces.get(i);
                let point1 = new cv.Point(face.x, face.y);
                let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
            }
            cv.imshow('canvasOutput', dst);
            // schedule the next one.
            let delay = 1000/FPS - (Date.now() - begin);
            setTimeout(processVideo, delay);
        } catch (err) {
            console.log(cv.exceptionFromPtr(err).msg)

        }
    };

  
        

</script>
</html>