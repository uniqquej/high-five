<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Document</title>
  <script src="opencv.js"></script>
  <script src="face-api.js"></script>
  <style>
    body {
      margin: 0;
      padding: 0;
      width: 100vw;
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
    }

    canvas {
      position: absolute;
    }
  </style>
</head>
<body>
  <!-- <div style="display: flex; flex-direction: column;">
    <video id="video" width="720" height="560" autoplay muted></video>
    <div id='output'></div>
  </div> -->
  <!-- <img id="imgfile"> -->
  <div class="container">
    <video id="video" width="640" height="480" autoplay playsinline muted style="position:absolute; top:0; left:0;"></video>
    <canvas id="canvas" width="640" height="480" style="position:absolute; top:0; left:0;"></canvas>
  </div>
  <canvas id="output_canvas"></canvas>
</body>
<script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const context = canvas.getContext("2d");
    const WIDTH = canvas.width;
    const HEIGHT = canvas.height;
    let boxWidth, boxHeigth, boxX, boxY;

Promise.all([
  faceapi.nets.tinyFaceDetector.loadFromUri("/"),
  faceapi.nets.faceLandmark68Net.loadFromUri("/"),
  faceapi.nets.faceRecognitionNet.loadFromUri("/"),
  faceapi.nets.faceExpressionNet.loadFromUri("/"),
]).then(startVideo);

function startVideo() {
  navigator.mediaDevices
    .getUserMedia({ video: true })
    .then(function (stream) {
      video.srcObject = stream;
    })
    .catch(function (err) {
      console.log(err);
    });
}


video.addEventListener("play", () => {
  const displaySize = { width: WIDTH, height: HEIGHT };
  let interval = setInterval(async () => {
    context.drawImage(video, 0, 0);
    const detections = await faceapi
      .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
    const resizedDetections = faceapi.resizeResults(detections, displaySize);

    if (detections.length != 0){
        video.pause();
        clearInterval(interval)
        const boxInfo = detections[0]._box
        boxWidth = boxInfo.width;
        boxHeight = boxInfo.height;
        boxX=boxInfo._x;
        boxY=boxInfo._y;
        context.beginPath();
        context.lineWidth = 2;
        context.strokeStyle = "#00ff00";
        context.strokeRect(boxInfo._x, boxInfo._y, boxInfo.width, boxInfo.height);

        img = new Image();
			  img.onload = function(){
				var canvas = document.getElementById("output_canvas");
				canvas.width = boxWidth;
				canvas.height = boxHeight;
				var ctx = canvas.getContext("2d");
				ctx.drawImage( img, boxX, boxY, boxWidth, boxHeight, 0, 0, boxWidth, boxHeight );
			};
			  img.src = canvas.toDataURL();
    }
    console.log(resizedDetections)}, 100);
});
</script>
</html>